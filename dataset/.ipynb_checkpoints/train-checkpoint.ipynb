{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e12eaa-87ee-46a1-a2fe-7e34ae5dfe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maniksinghsarmaal/mambaforge3/envs/sbin/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/maniksinghsarmaal/mambaforge3/envs/sbin/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = \"/Users/maniksinghsarmaal/Downloads/s_bin/dataset_copy\"\n",
    "input_shape = 224\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "\n",
    "#data transformation\n",
    "data_transforms = {\n",
    "   'train': transforms.Compose([\n",
    "       transforms.CenterCrop(input_shape),\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize(mean, std)\n",
    "   ]),\n",
    "   'val': transforms.Compose([\n",
    "       transforms.CenterCrop(input_shape),\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize(mean, std)\n",
    "   ]),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "   x: datasets.ImageFolder(\n",
    "       os.path.join(data_dir, x),\n",
    "       transform=data_transforms[x]\n",
    "   )\n",
    "   for x in ['train', 'val']\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "   x: torch.utils.data.DataLoader(\n",
    "       image_datasets[x], batch_size=32,\n",
    "       shuffle=True, num_workers=4\n",
    "   )\n",
    "   for x in ['train', 'val']\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "#print(dataset_sizes)\n",
    "class_names = image_datasets['train'].classes\n",
    "#print(class_names)\n",
    "device = torch.device(\"mps\")\n",
    "#print(device)## Load the model based on VGG19\n",
    "# Load the model based on MobileNetV2\n",
    "mobilenet_v2_based = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# Freeze the layers\n",
    "for param in mobilenet_v2_based.parameters():\n",
    "   param.requires_grad = False\n",
    "\n",
    "# Modify the last layer\n",
    "number_features = mobilenet_v2_based.classifier[1].in_features\n",
    "features = list(mobilenet_v2_based.classifier.children())[:-1]  # Remove last layer\n",
    "features.extend([torch.nn.Linear(number_features, len(class_names))])\n",
    "mobilenet_v2_based.classifier = torch.nn.Sequential(*features)\n",
    "\n",
    "mobilenet_v2_based = mobilenet_v2_based.to(device)\n",
    "\n",
    "print(mobilenet_v2_based)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(mobilenet_v2_based.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "mobilenet_v2_based = mobilenet_v2_based.to(device)\n",
    "\n",
    "#print(mobilenet_v2_based)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(mobilenet_v2_based.parameters(), lr=0.001, momentum=0.9)\n",
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "   since = time.time()\n",
    "\n",
    "   for epoch in range(num_epochs):\n",
    "       print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "       print('-' * 10)\n",
    "\n",
    "       #set model to trainable\n",
    "       # model.train()\n",
    "\n",
    "       train_loss = 0\n",
    "\n",
    "       # Iterate over data.\n",
    "       for i, data in enumerate(dataloaders['train']):\n",
    "           inputs , labels = data\n",
    "           inputs = inputs.to(device)\n",
    "           labels = labels.to(device)\n",
    "\n",
    "           optimizer.zero_grad()\n",
    "          \n",
    "           with torch.set_grad_enabled(True):\n",
    "               outputs  = model(inputs)\n",
    "               loss = criterion(outputs, labels)\n",
    "\n",
    "           loss.backward()\n",
    "           optimizer.step()\n",
    "\n",
    "           train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "           print('{} Loss: {:.4f}'.format(\n",
    "               'train', train_loss / dataset_sizes['train']))\n",
    "          \n",
    "   time_elapsed = time.time() - since\n",
    "   print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "       time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "   return model\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "   was_training = model.training\n",
    "   model.eval()\n",
    "   images_so_far = 0\n",
    "   fig = plt.figure()\n",
    "\n",
    "   with torch.no_grad():\n",
    "       for i, (inputs, labels) in enumerate(dataloaders['validation']):\n",
    "           inputs = inputs.to(device)\n",
    "           labels = labels.to(device)\n",
    "\n",
    "           outputs = model(inputs)\n",
    "           _, preds = torch.max(outputs, 1)\n",
    "\n",
    "           for j in range(inputs.size()[0]):\n",
    "               images_so_far += 1\n",
    "               ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "               ax.axis('off')\n",
    "               ax.set_title('predicted: {} truth: {}'.format(class_names[preds[j]], class_names[labels[j]]))\n",
    "               img = inputs.cpu().data[j].numpy().transpose((1, 2, 0))\n",
    "               img = std * img + mean\n",
    "               ax.imshow(img)\n",
    "\n",
    "               if images_so_far == num_images:\n",
    "                   model.train(mode=was_training)\n",
    "                   return\n",
    "       model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9d6760-abf4-41a9-9a68-ebb28dd22928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.0252\n",
      "train Loss: 0.0514\n",
      "train Loss: 0.0765\n",
      "train Loss: 0.1018\n",
      "train Loss: 0.1282\n",
      "train Loss: 0.1526\n",
      "train Loss: 0.1783\n",
      "train Loss: 0.2011\n",
      "train Loss: 0.2262\n",
      "train Loss: 0.2499\n",
      "train Loss: 0.2735\n",
      "train Loss: 0.2966\n",
      "train Loss: 0.3192\n",
      "train Loss: 0.3421\n",
      "train Loss: 0.3633\n",
      "train Loss: 0.3864\n",
      "train Loss: 0.4079\n",
      "train Loss: 0.4280\n",
      "train Loss: 0.4506\n",
      "train Loss: 0.4704\n",
      "train Loss: 0.4901\n",
      "train Loss: 0.5095\n",
      "train Loss: 0.5301\n",
      "train Loss: 0.5530\n",
      "train Loss: 0.5730\n",
      "train Loss: 0.5923\n",
      "train Loss: 0.6080\n",
      "train Loss: 0.6262\n",
      "train Loss: 0.6423\n",
      "train Loss: 0.6618\n",
      "train Loss: 0.6810\n",
      "train Loss: 0.6979\n",
      "train Loss: 0.7154\n",
      "train Loss: 0.7334\n",
      "train Loss: 0.7521\n",
      "train Loss: 0.7702\n",
      "train Loss: 0.7889\n",
      "train Loss: 0.8040\n",
      "train Loss: 0.8183\n",
      "train Loss: 0.8371\n",
      "train Loss: 0.8569\n",
      "train Loss: 0.8774\n",
      "train Loss: 0.8964\n",
      "train Loss: 0.9149\n",
      "train Loss: 0.9294\n",
      "train Loss: 0.9463\n",
      "train Loss: 0.9633\n",
      "train Loss: 0.9809\n",
      "train Loss: 0.9967\n",
      "train Loss: 1.0130\n",
      "train Loss: 1.0280\n",
      "train Loss: 1.0447\n",
      "train Loss: 1.0592\n",
      "train Loss: 1.0769\n",
      "train Loss: 1.0953\n",
      "train Loss: 1.1103\n",
      "train Loss: 1.1252\n",
      "train Loss: 1.1387\n",
      "train Loss: 1.1559\n",
      "train Loss: 1.1726\n",
      "train Loss: 1.1861\n",
      "train Loss: 1.2017\n",
      "train Loss: 1.2161\n",
      "train Loss: 1.2319\n",
      "train Loss: 1.2455\n",
      "train Loss: 1.2610\n",
      "train Loss: 1.2793\n",
      "train Loss: 1.2938\n",
      "train Loss: 1.3093\n",
      "train Loss: 1.3200\n",
      "train Loss: 1.3318\n",
      "train Loss: 1.3398\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.0141\n",
      "train Loss: 0.0284\n",
      "train Loss: 0.0419\n",
      "train Loss: 0.0570\n",
      "train Loss: 0.0700\n",
      "train Loss: 0.0809\n",
      "train Loss: 0.0937\n",
      "train Loss: 0.1047\n",
      "train Loss: 0.1183\n",
      "train Loss: 0.1303\n",
      "train Loss: 0.1419\n",
      "train Loss: 0.1571\n",
      "train Loss: 0.1713\n",
      "train Loss: 0.1846\n",
      "train Loss: 0.2006\n",
      "train Loss: 0.2127\n",
      "train Loss: 0.2278\n",
      "train Loss: 0.2404\n",
      "train Loss: 0.2522\n",
      "train Loss: 0.2677\n",
      "train Loss: 0.2844\n",
      "train Loss: 0.2979\n",
      "train Loss: 0.3141\n",
      "train Loss: 0.3278\n",
      "train Loss: 0.3432\n",
      "train Loss: 0.3543\n",
      "train Loss: 0.3659\n",
      "train Loss: 0.3800\n",
      "train Loss: 0.3946\n",
      "train Loss: 0.4095\n",
      "train Loss: 0.4198\n",
      "train Loss: 0.4341\n",
      "train Loss: 0.4486\n",
      "train Loss: 0.4610\n",
      "train Loss: 0.4740\n",
      "train Loss: 0.4864\n",
      "train Loss: 0.4969\n",
      "train Loss: 0.5063\n",
      "train Loss: 0.5178\n",
      "train Loss: 0.5325\n",
      "train Loss: 0.5470\n",
      "train Loss: 0.5585\n",
      "train Loss: 0.5711\n",
      "train Loss: 0.5832\n",
      "train Loss: 0.5923\n",
      "train Loss: 0.6030\n",
      "train Loss: 0.6180\n",
      "train Loss: 0.6293\n",
      "train Loss: 0.6407\n",
      "train Loss: 0.6550\n",
      "train Loss: 0.6680\n",
      "train Loss: 0.6835\n",
      "train Loss: 0.6943\n",
      "train Loss: 0.7042\n",
      "train Loss: 0.7173\n",
      "train Loss: 0.7308\n",
      "train Loss: 0.7451\n",
      "train Loss: 0.7565\n",
      "train Loss: 0.7674\n",
      "train Loss: 0.7807\n",
      "train Loss: 0.7912\n",
      "train Loss: 0.8030\n",
      "train Loss: 0.8186\n",
      "train Loss: 0.8301\n",
      "train Loss: 0.8437\n",
      "train Loss: 0.8543\n",
      "train Loss: 0.8653\n",
      "train Loss: 0.8762\n",
      "train Loss: 0.8904\n",
      "train Loss: 0.9014\n",
      "train Loss: 0.9140\n",
      "train Loss: 0.9206\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.0077\n",
      "train Loss: 0.0204\n",
      "train Loss: 0.0358\n",
      "train Loss: 0.0487\n",
      "train Loss: 0.0577\n",
      "train Loss: 0.0679\n",
      "train Loss: 0.0778\n",
      "train Loss: 0.0907\n",
      "train Loss: 0.1052\n",
      "train Loss: 0.1158\n",
      "train Loss: 0.1263\n",
      "train Loss: 0.1422\n",
      "train Loss: 0.1533\n",
      "train Loss: 0.1623\n",
      "train Loss: 0.1782\n",
      "train Loss: 0.1880\n",
      "train Loss: 0.2020\n",
      "train Loss: 0.2114\n",
      "train Loss: 0.2214\n",
      "train Loss: 0.2299\n",
      "train Loss: 0.2410\n",
      "train Loss: 0.2502\n",
      "train Loss: 0.2597\n",
      "train Loss: 0.2726\n",
      "train Loss: 0.2843\n",
      "train Loss: 0.2947\n",
      "train Loss: 0.3059\n",
      "train Loss: 0.3170\n",
      "train Loss: 0.3274\n",
      "train Loss: 0.3370\n",
      "train Loss: 0.3503\n",
      "train Loss: 0.3624\n",
      "train Loss: 0.3716\n",
      "train Loss: 0.3821\n",
      "train Loss: 0.3933\n",
      "train Loss: 0.4083\n",
      "train Loss: 0.4187\n",
      "train Loss: 0.4273\n",
      "train Loss: 0.4365\n",
      "train Loss: 0.4483\n",
      "train Loss: 0.4593\n",
      "train Loss: 0.4749\n",
      "train Loss: 0.4870\n",
      "train Loss: 0.4992\n",
      "train Loss: 0.5133\n",
      "train Loss: 0.5263\n",
      "train Loss: 0.5373\n",
      "train Loss: 0.5484\n",
      "train Loss: 0.5626\n",
      "train Loss: 0.5761\n",
      "train Loss: 0.5872\n",
      "train Loss: 0.5967\n",
      "train Loss: 0.6070\n",
      "train Loss: 0.6177\n",
      "train Loss: 0.6286\n",
      "train Loss: 0.6415\n",
      "train Loss: 0.6512\n",
      "train Loss: 0.6621\n",
      "train Loss: 0.6761\n",
      "train Loss: 0.6896\n",
      "train Loss: 0.6986\n",
      "train Loss: 0.7065\n",
      "train Loss: 0.7164\n",
      "train Loss: 0.7268\n",
      "train Loss: 0.7372\n",
      "train Loss: 0.7481\n",
      "train Loss: 0.7591\n",
      "train Loss: 0.7712\n",
      "train Loss: 0.7827\n",
      "train Loss: 0.7922\n",
      "train Loss: 0.8000\n",
      "train Loss: 0.8058\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.0078\n",
      "train Loss: 0.0167\n",
      "train Loss: 0.0257\n",
      "train Loss: 0.0393\n",
      "train Loss: 0.0473\n",
      "train Loss: 0.0626\n",
      "train Loss: 0.0728\n",
      "train Loss: 0.0849\n",
      "train Loss: 0.0952\n",
      "train Loss: 0.1071\n",
      "train Loss: 0.1187\n",
      "train Loss: 0.1285\n",
      "train Loss: 0.1395\n",
      "train Loss: 0.1507\n",
      "train Loss: 0.1616\n",
      "train Loss: 0.1722\n",
      "train Loss: 0.1825\n",
      "train Loss: 0.1930\n",
      "train Loss: 0.2065\n",
      "train Loss: 0.2170\n",
      "train Loss: 0.2267\n",
      "train Loss: 0.2389\n",
      "train Loss: 0.2487\n",
      "train Loss: 0.2575\n",
      "train Loss: 0.2664\n",
      "train Loss: 0.2770\n",
      "train Loss: 0.2875\n",
      "train Loss: 0.2970\n",
      "train Loss: 0.3051\n",
      "train Loss: 0.3162\n",
      "train Loss: 0.3266\n",
      "train Loss: 0.3352\n",
      "train Loss: 0.3447\n",
      "train Loss: 0.3538\n",
      "train Loss: 0.3637\n",
      "train Loss: 0.3731\n",
      "train Loss: 0.3842\n",
      "train Loss: 0.3940\n",
      "train Loss: 0.4066\n",
      "train Loss: 0.4148\n",
      "train Loss: 0.4292\n",
      "train Loss: 0.4391\n",
      "train Loss: 0.4501\n",
      "train Loss: 0.4578\n",
      "train Loss: 0.4682\n",
      "train Loss: 0.4803\n",
      "train Loss: 0.4908\n",
      "train Loss: 0.5025\n",
      "train Loss: 0.5124\n",
      "train Loss: 0.5229\n",
      "train Loss: 0.5302\n",
      "train Loss: 0.5378\n",
      "train Loss: 0.5493\n",
      "train Loss: 0.5635\n",
      "train Loss: 0.5751\n",
      "train Loss: 0.5853\n",
      "train Loss: 0.5956\n",
      "train Loss: 0.6039\n",
      "train Loss: 0.6133\n",
      "train Loss: 0.6204\n",
      "train Loss: 0.6295\n",
      "train Loss: 0.6394\n",
      "train Loss: 0.6485\n",
      "train Loss: 0.6596\n",
      "train Loss: 0.6711\n",
      "train Loss: 0.6797\n",
      "train Loss: 0.6872\n",
      "train Loss: 0.6969\n",
      "train Loss: 0.7065\n",
      "train Loss: 0.7142\n",
      "train Loss: 0.7207\n",
      "train Loss: 0.7247\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.0137\n",
      "train Loss: 0.0237\n",
      "train Loss: 0.0304\n",
      "train Loss: 0.0352\n",
      "train Loss: 0.0406\n",
      "train Loss: 0.0519\n",
      "train Loss: 0.0604\n",
      "train Loss: 0.0723\n",
      "train Loss: 0.0825\n",
      "train Loss: 0.0925\n",
      "train Loss: 0.1051\n",
      "train Loss: 0.1157\n",
      "train Loss: 0.1246\n",
      "train Loss: 0.1376\n",
      "train Loss: 0.1478\n",
      "train Loss: 0.1548\n",
      "train Loss: 0.1651\n",
      "train Loss: 0.1756\n",
      "train Loss: 0.1814\n",
      "train Loss: 0.1904\n",
      "train Loss: 0.1996\n",
      "train Loss: 0.2130\n",
      "train Loss: 0.2251\n",
      "train Loss: 0.2342\n",
      "train Loss: 0.2444\n",
      "train Loss: 0.2554\n",
      "train Loss: 0.2646\n",
      "train Loss: 0.2744\n",
      "train Loss: 0.2846\n",
      "train Loss: 0.2942\n",
      "train Loss: 0.3033\n",
      "train Loss: 0.3136\n",
      "train Loss: 0.3253\n",
      "train Loss: 0.3372\n",
      "train Loss: 0.3465\n",
      "train Loss: 0.3573\n",
      "train Loss: 0.3659\n",
      "train Loss: 0.3752\n",
      "train Loss: 0.3857\n",
      "train Loss: 0.3939\n",
      "train Loss: 0.4050\n",
      "train Loss: 0.4127\n",
      "train Loss: 0.4207\n",
      "train Loss: 0.4312\n",
      "train Loss: 0.4396\n",
      "train Loss: 0.4478\n",
      "train Loss: 0.4555\n",
      "train Loss: 0.4636\n",
      "train Loss: 0.4740\n",
      "train Loss: 0.4805\n",
      "train Loss: 0.4917\n",
      "train Loss: 0.5012\n",
      "train Loss: 0.5111\n",
      "train Loss: 0.5167\n",
      "train Loss: 0.5256\n",
      "train Loss: 0.5395\n",
      "train Loss: 0.5515\n",
      "train Loss: 0.5609\n",
      "train Loss: 0.5673\n",
      "train Loss: 0.5763\n",
      "train Loss: 0.5850\n",
      "train Loss: 0.5939\n",
      "train Loss: 0.6048\n",
      "train Loss: 0.6194\n",
      "train Loss: 0.6283\n",
      "train Loss: 0.6357\n",
      "train Loss: 0.6449\n",
      "train Loss: 0.6554\n",
      "train Loss: 0.6665\n",
      "train Loss: 0.6741\n",
      "train Loss: 0.6820\n",
      "train Loss: 0.6855\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.0066\n",
      "train Loss: 0.0153\n",
      "train Loss: 0.0236\n",
      "train Loss: 0.0352\n",
      "train Loss: 0.0476\n",
      "train Loss: 0.0538\n",
      "train Loss: 0.0655\n",
      "train Loss: 0.0717\n",
      "train Loss: 0.0799\n",
      "train Loss: 0.0927\n",
      "train Loss: 0.1005\n",
      "train Loss: 0.1095\n",
      "train Loss: 0.1156\n",
      "train Loss: 0.1263\n",
      "train Loss: 0.1342\n",
      "train Loss: 0.1463\n",
      "train Loss: 0.1561\n",
      "train Loss: 0.1640\n",
      "train Loss: 0.1714\n",
      "train Loss: 0.1815\n",
      "train Loss: 0.1904\n",
      "train Loss: 0.1952\n",
      "train Loss: 0.2052\n",
      "train Loss: 0.2102\n",
      "train Loss: 0.2169\n",
      "train Loss: 0.2262\n",
      "train Loss: 0.2336\n",
      "train Loss: 0.2420\n",
      "train Loss: 0.2522\n",
      "train Loss: 0.2592\n",
      "train Loss: 0.2709\n",
      "train Loss: 0.2815\n",
      "train Loss: 0.2891\n",
      "train Loss: 0.2982\n",
      "train Loss: 0.3048\n",
      "train Loss: 0.3164\n",
      "train Loss: 0.3278\n",
      "train Loss: 0.3350\n",
      "train Loss: 0.3413\n",
      "train Loss: 0.3500\n",
      "train Loss: 0.3611\n",
      "train Loss: 0.3714\n",
      "train Loss: 0.3814\n",
      "train Loss: 0.3936\n",
      "train Loss: 0.4013\n",
      "train Loss: 0.4105\n",
      "train Loss: 0.4217\n",
      "train Loss: 0.4283\n",
      "train Loss: 0.4355\n",
      "train Loss: 0.4458\n",
      "train Loss: 0.4570\n",
      "train Loss: 0.4646\n",
      "train Loss: 0.4747\n",
      "train Loss: 0.4831\n",
      "train Loss: 0.4912\n",
      "train Loss: 0.4999\n",
      "train Loss: 0.5088\n",
      "train Loss: 0.5215\n",
      "train Loss: 0.5280\n",
      "train Loss: 0.5383\n",
      "train Loss: 0.5477\n",
      "train Loss: 0.5545\n",
      "train Loss: 0.5670\n",
      "train Loss: 0.5755\n",
      "train Loss: 0.5842\n",
      "train Loss: 0.5929\n",
      "train Loss: 0.6005\n",
      "train Loss: 0.6096\n",
      "train Loss: 0.6164\n",
      "train Loss: 0.6310\n",
      "train Loss: 0.6396\n",
      "train Loss: 0.6444\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.0081\n",
      "train Loss: 0.0155\n",
      "train Loss: 0.0234\n",
      "train Loss: 0.0342\n",
      "train Loss: 0.0427\n",
      "train Loss: 0.0515\n",
      "train Loss: 0.0604\n",
      "train Loss: 0.0666\n",
      "train Loss: 0.0747\n",
      "train Loss: 0.0812\n",
      "train Loss: 0.0908\n",
      "train Loss: 0.0975\n",
      "train Loss: 0.1089\n",
      "train Loss: 0.1160\n",
      "train Loss: 0.1262\n",
      "train Loss: 0.1370\n",
      "train Loss: 0.1481\n",
      "train Loss: 0.1554\n",
      "train Loss: 0.1632\n",
      "train Loss: 0.1749\n",
      "train Loss: 0.1820\n",
      "train Loss: 0.1877\n",
      "train Loss: 0.1966\n",
      "train Loss: 0.2046\n",
      "train Loss: 0.2124\n",
      "train Loss: 0.2204\n",
      "train Loss: 0.2285\n",
      "train Loss: 0.2380\n",
      "train Loss: 0.2482\n",
      "train Loss: 0.2574\n",
      "train Loss: 0.2685\n",
      "train Loss: 0.2784\n",
      "train Loss: 0.2859\n",
      "train Loss: 0.2938\n",
      "train Loss: 0.2992\n",
      "train Loss: 0.3093\n",
      "train Loss: 0.3226\n",
      "train Loss: 0.3313\n",
      "train Loss: 0.3425\n",
      "train Loss: 0.3502\n",
      "train Loss: 0.3567\n",
      "train Loss: 0.3667\n",
      "train Loss: 0.3759\n",
      "train Loss: 0.3857\n",
      "train Loss: 0.3949\n",
      "train Loss: 0.4033\n",
      "train Loss: 0.4112\n",
      "train Loss: 0.4200\n",
      "train Loss: 0.4287\n",
      "train Loss: 0.4390\n",
      "train Loss: 0.4510\n",
      "train Loss: 0.4622\n",
      "train Loss: 0.4680\n",
      "train Loss: 0.4780\n",
      "train Loss: 0.4886\n",
      "train Loss: 0.4955\n",
      "train Loss: 0.5041\n",
      "train Loss: 0.5138\n",
      "train Loss: 0.5224\n",
      "train Loss: 0.5287\n",
      "train Loss: 0.5371\n",
      "train Loss: 0.5487\n",
      "train Loss: 0.5558\n",
      "train Loss: 0.5641\n",
      "train Loss: 0.5750\n",
      "train Loss: 0.5823\n",
      "train Loss: 0.5958\n",
      "train Loss: 0.6026\n",
      "train Loss: 0.6125\n",
      "train Loss: 0.6216\n",
      "train Loss: 0.6313\n",
      "train Loss: 0.6367\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.0065\n",
      "train Loss: 0.0132\n",
      "train Loss: 0.0193\n",
      "train Loss: 0.0264\n",
      "train Loss: 0.0379\n",
      "train Loss: 0.0453\n",
      "train Loss: 0.0523\n",
      "train Loss: 0.0618\n",
      "train Loss: 0.0694\n",
      "train Loss: 0.0744\n",
      "train Loss: 0.0820\n",
      "train Loss: 0.0917\n",
      "train Loss: 0.0964\n",
      "train Loss: 0.1039\n",
      "train Loss: 0.1112\n",
      "train Loss: 0.1246\n",
      "train Loss: 0.1339\n",
      "train Loss: 0.1407\n",
      "train Loss: 0.1470\n",
      "train Loss: 0.1565\n",
      "train Loss: 0.1638\n",
      "train Loss: 0.1691\n",
      "train Loss: 0.1756\n",
      "train Loss: 0.1850\n",
      "train Loss: 0.1911\n",
      "train Loss: 0.1998\n",
      "train Loss: 0.2150\n",
      "train Loss: 0.2246\n",
      "train Loss: 0.2328\n",
      "train Loss: 0.2386\n",
      "train Loss: 0.2513\n",
      "train Loss: 0.2600\n",
      "train Loss: 0.2672\n",
      "train Loss: 0.2746\n",
      "train Loss: 0.2850\n",
      "train Loss: 0.2954\n",
      "train Loss: 0.3098\n",
      "train Loss: 0.3169\n",
      "train Loss: 0.3281\n",
      "train Loss: 0.3353\n",
      "train Loss: 0.3399\n",
      "train Loss: 0.3514\n",
      "train Loss: 0.3592\n",
      "train Loss: 0.3661\n",
      "train Loss: 0.3746\n",
      "train Loss: 0.3843\n",
      "train Loss: 0.3904\n",
      "train Loss: 0.3979\n",
      "train Loss: 0.4065\n",
      "train Loss: 0.4144\n",
      "train Loss: 0.4257\n",
      "train Loss: 0.4364\n",
      "train Loss: 0.4452\n",
      "train Loss: 0.4522\n",
      "train Loss: 0.4583\n",
      "train Loss: 0.4635\n",
      "train Loss: 0.4740\n",
      "train Loss: 0.4839\n",
      "train Loss: 0.4923\n",
      "train Loss: 0.5025\n",
      "train Loss: 0.5087\n",
      "train Loss: 0.5149\n",
      "train Loss: 0.5237\n",
      "train Loss: 0.5322\n",
      "train Loss: 0.5444\n",
      "train Loss: 0.5512\n",
      "train Loss: 0.5648\n",
      "train Loss: 0.5737\n",
      "train Loss: 0.5819\n",
      "train Loss: 0.5870\n",
      "train Loss: 0.5963\n",
      "train Loss: 0.6018\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.0092\n",
      "train Loss: 0.0165\n",
      "train Loss: 0.0238\n",
      "train Loss: 0.0367\n",
      "train Loss: 0.0478\n",
      "train Loss: 0.0551\n",
      "train Loss: 0.0634\n",
      "train Loss: 0.0703\n",
      "train Loss: 0.0776\n",
      "train Loss: 0.0849\n",
      "train Loss: 0.0922\n",
      "train Loss: 0.1020\n",
      "train Loss: 0.1125\n",
      "train Loss: 0.1218\n",
      "train Loss: 0.1296\n",
      "train Loss: 0.1382\n",
      "train Loss: 0.1450\n",
      "train Loss: 0.1533\n",
      "train Loss: 0.1621\n",
      "train Loss: 0.1703\n",
      "train Loss: 0.1783\n",
      "train Loss: 0.1874\n",
      "train Loss: 0.1988\n",
      "train Loss: 0.2053\n",
      "train Loss: 0.2117\n",
      "train Loss: 0.2196\n",
      "train Loss: 0.2256\n",
      "train Loss: 0.2338\n",
      "train Loss: 0.2405\n",
      "train Loss: 0.2492\n",
      "train Loss: 0.2563\n",
      "train Loss: 0.2623\n",
      "train Loss: 0.2718\n",
      "train Loss: 0.2792\n",
      "train Loss: 0.2853\n",
      "train Loss: 0.2930\n",
      "train Loss: 0.3054\n",
      "train Loss: 0.3119\n",
      "train Loss: 0.3214\n",
      "train Loss: 0.3340\n",
      "train Loss: 0.3410\n",
      "train Loss: 0.3472\n",
      "train Loss: 0.3537\n",
      "train Loss: 0.3620\n",
      "train Loss: 0.3694\n",
      "train Loss: 0.3771\n",
      "train Loss: 0.3851\n",
      "train Loss: 0.3960\n",
      "train Loss: 0.4054\n",
      "train Loss: 0.4131\n",
      "train Loss: 0.4204\n",
      "train Loss: 0.4270\n",
      "train Loss: 0.4345\n",
      "train Loss: 0.4400\n",
      "train Loss: 0.4468\n",
      "train Loss: 0.4554\n",
      "train Loss: 0.4631\n",
      "train Loss: 0.4685\n",
      "train Loss: 0.4794\n",
      "train Loss: 0.4882\n",
      "train Loss: 0.4963\n",
      "train Loss: 0.5061\n",
      "train Loss: 0.5162\n",
      "train Loss: 0.5247\n",
      "train Loss: 0.5406\n",
      "train Loss: 0.5465\n",
      "train Loss: 0.5551\n",
      "train Loss: 0.5623\n",
      "train Loss: 0.5693\n",
      "train Loss: 0.5781\n",
      "train Loss: 0.5857\n",
      "train Loss: 0.5902\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.0064\n",
      "train Loss: 0.0127\n",
      "train Loss: 0.0207\n",
      "train Loss: 0.0281\n",
      "train Loss: 0.0400\n",
      "train Loss: 0.0482\n",
      "train Loss: 0.0566\n",
      "train Loss: 0.0635\n",
      "train Loss: 0.0726\n",
      "train Loss: 0.0823\n",
      "train Loss: 0.0920\n",
      "train Loss: 0.1002\n",
      "train Loss: 0.1093\n",
      "train Loss: 0.1188\n",
      "train Loss: 0.1246\n",
      "train Loss: 0.1321\n",
      "train Loss: 0.1404\n",
      "train Loss: 0.1464\n",
      "train Loss: 0.1557\n",
      "train Loss: 0.1605\n",
      "train Loss: 0.1666\n",
      "train Loss: 0.1744\n",
      "train Loss: 0.1829\n",
      "train Loss: 0.1911\n",
      "train Loss: 0.2002\n",
      "train Loss: 0.2090\n",
      "train Loss: 0.2160\n",
      "train Loss: 0.2252\n",
      "train Loss: 0.2337\n",
      "train Loss: 0.2402\n",
      "train Loss: 0.2463\n",
      "train Loss: 0.2551\n",
      "train Loss: 0.2629\n",
      "train Loss: 0.2742\n",
      "train Loss: 0.2811\n",
      "train Loss: 0.2897\n",
      "train Loss: 0.2971\n",
      "train Loss: 0.3054\n",
      "train Loss: 0.3163\n",
      "train Loss: 0.3206\n",
      "train Loss: 0.3270\n",
      "train Loss: 0.3349\n",
      "train Loss: 0.3480\n",
      "train Loss: 0.3561\n",
      "train Loss: 0.3625\n",
      "train Loss: 0.3706\n",
      "train Loss: 0.3769\n",
      "train Loss: 0.3871\n",
      "train Loss: 0.4024\n",
      "train Loss: 0.4089\n",
      "train Loss: 0.4182\n",
      "train Loss: 0.4260\n",
      "train Loss: 0.4369\n",
      "train Loss: 0.4440\n",
      "train Loss: 0.4516\n",
      "train Loss: 0.4584\n",
      "train Loss: 0.4705\n",
      "train Loss: 0.4783\n",
      "train Loss: 0.4845\n",
      "train Loss: 0.4948\n",
      "train Loss: 0.5033\n",
      "train Loss: 0.5125\n",
      "train Loss: 0.5193\n",
      "train Loss: 0.5239\n",
      "train Loss: 0.5321\n",
      "train Loss: 0.5382\n",
      "train Loss: 0.5448\n",
      "train Loss: 0.5543\n",
      "train Loss: 0.5609\n",
      "train Loss: 0.5675\n",
      "train Loss: 0.5754\n",
      "train Loss: 0.5787\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.0063\n",
      "train Loss: 0.0126\n",
      "train Loss: 0.0197\n",
      "train Loss: 0.0318\n",
      "train Loss: 0.0378\n",
      "train Loss: 0.0466\n",
      "train Loss: 0.0539\n",
      "train Loss: 0.0602\n",
      "train Loss: 0.0710\n",
      "train Loss: 0.0798\n",
      "train Loss: 0.0903\n",
      "train Loss: 0.0955\n",
      "train Loss: 0.1034\n",
      "train Loss: 0.1122\n",
      "train Loss: 0.1200\n",
      "train Loss: 0.1283\n",
      "train Loss: 0.1359\n",
      "train Loss: 0.1455\n",
      "train Loss: 0.1567\n",
      "train Loss: 0.1681\n",
      "train Loss: 0.1768\n",
      "train Loss: 0.1860\n",
      "train Loss: 0.1933\n",
      "train Loss: 0.1988\n",
      "train Loss: 0.2063\n",
      "train Loss: 0.2130\n",
      "train Loss: 0.2221\n",
      "train Loss: 0.2317\n",
      "train Loss: 0.2381\n",
      "train Loss: 0.2443\n",
      "train Loss: 0.2529\n",
      "train Loss: 0.2595\n",
      "train Loss: 0.2698\n",
      "train Loss: 0.2769\n",
      "train Loss: 0.2840\n",
      "train Loss: 0.2907\n",
      "train Loss: 0.2988\n",
      "train Loss: 0.3039\n",
      "train Loss: 0.3115\n",
      "train Loss: 0.3198\n",
      "train Loss: 0.3294\n",
      "train Loss: 0.3376\n",
      "train Loss: 0.3442\n",
      "train Loss: 0.3536\n",
      "train Loss: 0.3602\n",
      "train Loss: 0.3666\n",
      "train Loss: 0.3784\n",
      "train Loss: 0.3835\n",
      "train Loss: 0.3910\n",
      "train Loss: 0.3959\n",
      "train Loss: 0.4029\n",
      "train Loss: 0.4108\n",
      "train Loss: 0.4185\n",
      "train Loss: 0.4232\n",
      "train Loss: 0.4290\n",
      "train Loss: 0.4370\n",
      "train Loss: 0.4407\n",
      "train Loss: 0.4494\n",
      "train Loss: 0.4557\n",
      "train Loss: 0.4626\n",
      "train Loss: 0.4738\n",
      "train Loss: 0.4809\n",
      "train Loss: 0.4864\n",
      "train Loss: 0.4961\n",
      "train Loss: 0.5057\n",
      "train Loss: 0.5128\n",
      "train Loss: 0.5230\n",
      "train Loss: 0.5303\n",
      "train Loss: 0.5370\n",
      "train Loss: 0.5464\n",
      "train Loss: 0.5546\n",
      "train Loss: 0.5570\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.0063\n",
      "train Loss: 0.0156\n",
      "train Loss: 0.0217\n",
      "train Loss: 0.0312\n",
      "train Loss: 0.0415\n",
      "train Loss: 0.0483\n",
      "train Loss: 0.0556\n",
      "train Loss: 0.0639\n",
      "train Loss: 0.0683\n",
      "train Loss: 0.0753\n",
      "train Loss: 0.0823\n",
      "train Loss: 0.0920\n",
      "train Loss: 0.0962\n",
      "train Loss: 0.1027\n",
      "train Loss: 0.1090\n",
      "train Loss: 0.1186\n",
      "train Loss: 0.1288\n",
      "train Loss: 0.1368\n",
      "train Loss: 0.1437\n",
      "train Loss: 0.1538\n",
      "train Loss: 0.1620\n",
      "train Loss: 0.1690\n",
      "train Loss: 0.1765\n",
      "train Loss: 0.1848\n",
      "train Loss: 0.1889\n",
      "train Loss: 0.1953\n",
      "train Loss: 0.2002\n",
      "train Loss: 0.2063\n",
      "train Loss: 0.2133\n",
      "train Loss: 0.2201\n",
      "train Loss: 0.2279\n",
      "train Loss: 0.2337\n",
      "train Loss: 0.2401\n",
      "train Loss: 0.2485\n",
      "train Loss: 0.2549\n",
      "train Loss: 0.2632\n",
      "train Loss: 0.2731\n",
      "train Loss: 0.2862\n",
      "train Loss: 0.2986\n",
      "train Loss: 0.3090\n",
      "train Loss: 0.3199\n",
      "train Loss: 0.3264\n",
      "train Loss: 0.3316\n",
      "train Loss: 0.3403\n",
      "train Loss: 0.3494\n",
      "train Loss: 0.3555\n",
      "train Loss: 0.3638\n",
      "train Loss: 0.3692\n",
      "train Loss: 0.3774\n",
      "train Loss: 0.3855\n",
      "train Loss: 0.3908\n",
      "train Loss: 0.3998\n",
      "train Loss: 0.4071\n",
      "train Loss: 0.4182\n",
      "train Loss: 0.4239\n",
      "train Loss: 0.4322\n",
      "train Loss: 0.4432\n",
      "train Loss: 0.4527\n",
      "train Loss: 0.4585\n",
      "train Loss: 0.4651\n",
      "train Loss: 0.4750\n",
      "train Loss: 0.4847\n",
      "train Loss: 0.4908\n",
      "train Loss: 0.4977\n",
      "train Loss: 0.5049\n",
      "train Loss: 0.5115\n",
      "train Loss: 0.5162\n",
      "train Loss: 0.5241\n",
      "train Loss: 0.5318\n",
      "train Loss: 0.5375\n",
      "train Loss: 0.5419\n",
      "train Loss: 0.5454\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.0105\n",
      "train Loss: 0.0162\n",
      "train Loss: 0.0208\n",
      "train Loss: 0.0267\n",
      "train Loss: 0.0336\n",
      "train Loss: 0.0414\n",
      "train Loss: 0.0495\n",
      "train Loss: 0.0583\n",
      "train Loss: 0.0661\n",
      "train Loss: 0.0726\n",
      "train Loss: 0.0789\n",
      "train Loss: 0.0857\n",
      "train Loss: 0.0908\n",
      "train Loss: 0.0977\n",
      "train Loss: 0.1045\n",
      "train Loss: 0.1139\n",
      "train Loss: 0.1243\n",
      "train Loss: 0.1292\n",
      "train Loss: 0.1384\n",
      "train Loss: 0.1420\n",
      "train Loss: 0.1463\n",
      "train Loss: 0.1529\n",
      "train Loss: 0.1590\n",
      "train Loss: 0.1705\n",
      "train Loss: 0.1759\n",
      "train Loss: 0.1850\n",
      "train Loss: 0.1909\n",
      "train Loss: 0.2023\n",
      "train Loss: 0.2078\n",
      "train Loss: 0.2132\n",
      "train Loss: 0.2204\n",
      "train Loss: 0.2267\n",
      "train Loss: 0.2358\n",
      "train Loss: 0.2426\n",
      "train Loss: 0.2488\n",
      "train Loss: 0.2564\n",
      "train Loss: 0.2663\n",
      "train Loss: 0.2759\n",
      "train Loss: 0.2821\n",
      "train Loss: 0.2904\n",
      "train Loss: 0.2984\n",
      "train Loss: 0.3050\n",
      "train Loss: 0.3103\n",
      "train Loss: 0.3185\n",
      "train Loss: 0.3267\n",
      "train Loss: 0.3322\n",
      "train Loss: 0.3412\n",
      "train Loss: 0.3467\n",
      "train Loss: 0.3559\n",
      "train Loss: 0.3640\n",
      "train Loss: 0.3724\n",
      "train Loss: 0.3823\n",
      "train Loss: 0.3882\n",
      "train Loss: 0.3934\n",
      "train Loss: 0.4023\n",
      "train Loss: 0.4088\n",
      "train Loss: 0.4159\n",
      "train Loss: 0.4259\n",
      "train Loss: 0.4349\n",
      "train Loss: 0.4435\n",
      "train Loss: 0.4515\n",
      "train Loss: 0.4619\n",
      "train Loss: 0.4672\n",
      "train Loss: 0.4744\n",
      "train Loss: 0.4854\n",
      "train Loss: 0.4918\n",
      "train Loss: 0.4990\n",
      "train Loss: 0.5064\n",
      "train Loss: 0.5157\n",
      "train Loss: 0.5226\n",
      "train Loss: 0.5323\n",
      "train Loss: 0.5355\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.0062\n",
      "train Loss: 0.0164\n",
      "train Loss: 0.0211\n",
      "train Loss: 0.0285\n",
      "train Loss: 0.0354\n",
      "train Loss: 0.0422\n",
      "train Loss: 0.0488\n",
      "train Loss: 0.0549\n",
      "train Loss: 0.0604\n",
      "train Loss: 0.0681\n",
      "train Loss: 0.0736\n",
      "train Loss: 0.0805\n",
      "train Loss: 0.0870\n",
      "train Loss: 0.0933\n",
      "train Loss: 0.1012\n",
      "train Loss: 0.1103\n",
      "train Loss: 0.1178\n",
      "train Loss: 0.1260\n",
      "train Loss: 0.1338\n",
      "train Loss: 0.1404\n",
      "train Loss: 0.1478\n",
      "train Loss: 0.1547\n",
      "train Loss: 0.1602\n",
      "train Loss: 0.1690\n",
      "train Loss: 0.1783\n",
      "train Loss: 0.1869\n",
      "train Loss: 0.1951\n",
      "train Loss: 0.2010\n",
      "train Loss: 0.2091\n",
      "train Loss: 0.2133\n",
      "train Loss: 0.2207\n",
      "train Loss: 0.2272\n",
      "train Loss: 0.2364\n",
      "train Loss: 0.2420\n",
      "train Loss: 0.2515\n",
      "train Loss: 0.2586\n",
      "train Loss: 0.2660\n",
      "train Loss: 0.2753\n",
      "train Loss: 0.2818\n",
      "train Loss: 0.2938\n",
      "train Loss: 0.3005\n",
      "train Loss: 0.3054\n",
      "train Loss: 0.3133\n",
      "train Loss: 0.3191\n",
      "train Loss: 0.3273\n",
      "train Loss: 0.3382\n",
      "train Loss: 0.3446\n",
      "train Loss: 0.3496\n",
      "train Loss: 0.3546\n",
      "train Loss: 0.3595\n",
      "train Loss: 0.3652\n",
      "train Loss: 0.3714\n",
      "train Loss: 0.3805\n",
      "train Loss: 0.3906\n",
      "train Loss: 0.3984\n",
      "train Loss: 0.4062\n",
      "train Loss: 0.4120\n",
      "train Loss: 0.4190\n",
      "train Loss: 0.4261\n",
      "train Loss: 0.4361\n",
      "train Loss: 0.4432\n",
      "train Loss: 0.4500\n",
      "train Loss: 0.4573\n",
      "train Loss: 0.4634\n",
      "train Loss: 0.4678\n",
      "train Loss: 0.4789\n",
      "train Loss: 0.4851\n",
      "train Loss: 0.4925\n",
      "train Loss: 0.5026\n",
      "train Loss: 0.5085\n",
      "train Loss: 0.5146\n",
      "train Loss: 0.5225\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.0048\n",
      "train Loss: 0.0124\n",
      "train Loss: 0.0206\n",
      "train Loss: 0.0289\n",
      "train Loss: 0.0338\n",
      "train Loss: 0.0403\n",
      "train Loss: 0.0475\n",
      "train Loss: 0.0523\n",
      "train Loss: 0.0605\n",
      "train Loss: 0.0674\n",
      "train Loss: 0.0787\n",
      "train Loss: 0.0860\n",
      "train Loss: 0.0983\n",
      "train Loss: 0.1061\n",
      "train Loss: 0.1137\n",
      "train Loss: 0.1208\n",
      "train Loss: 0.1296\n",
      "train Loss: 0.1371\n",
      "train Loss: 0.1437\n",
      "train Loss: 0.1499\n",
      "train Loss: 0.1613\n",
      "train Loss: 0.1685\n",
      "train Loss: 0.1737\n",
      "train Loss: 0.1800\n",
      "train Loss: 0.1882\n",
      "train Loss: 0.1978\n",
      "train Loss: 0.2034\n",
      "train Loss: 0.2090\n",
      "train Loss: 0.2159\n",
      "train Loss: 0.2208\n",
      "train Loss: 0.2265\n",
      "train Loss: 0.2316\n",
      "train Loss: 0.2372\n",
      "train Loss: 0.2452\n",
      "train Loss: 0.2536\n",
      "train Loss: 0.2640\n",
      "train Loss: 0.2695\n",
      "train Loss: 0.2813\n",
      "train Loss: 0.2912\n",
      "train Loss: 0.2990\n",
      "train Loss: 0.3064\n",
      "train Loss: 0.3140\n",
      "train Loss: 0.3235\n",
      "train Loss: 0.3311\n",
      "train Loss: 0.3403\n",
      "train Loss: 0.3450\n",
      "train Loss: 0.3546\n",
      "train Loss: 0.3597\n",
      "train Loss: 0.3649\n",
      "train Loss: 0.3713\n",
      "train Loss: 0.3779\n",
      "train Loss: 0.3824\n",
      "train Loss: 0.3907\n",
      "train Loss: 0.4014\n",
      "train Loss: 0.4073\n",
      "train Loss: 0.4127\n",
      "train Loss: 0.4214\n",
      "train Loss: 0.4309\n",
      "train Loss: 0.4357\n",
      "train Loss: 0.4418\n",
      "train Loss: 0.4464\n",
      "train Loss: 0.4527\n",
      "train Loss: 0.4623\n",
      "train Loss: 0.4687\n",
      "train Loss: 0.4741\n",
      "train Loss: 0.4814\n",
      "train Loss: 0.4856\n",
      "train Loss: 0.4918\n",
      "train Loss: 0.4997\n",
      "train Loss: 0.5083\n",
      "train Loss: 0.5211\n",
      "train Loss: 0.5250\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.0085\n",
      "train Loss: 0.0153\n",
      "train Loss: 0.0250\n",
      "train Loss: 0.0298\n",
      "train Loss: 0.0413\n",
      "train Loss: 0.0509\n",
      "train Loss: 0.0575\n",
      "train Loss: 0.0641\n",
      "train Loss: 0.0715\n",
      "train Loss: 0.0788\n",
      "train Loss: 0.0884\n",
      "train Loss: 0.0935\n",
      "train Loss: 0.0985\n",
      "train Loss: 0.1046\n",
      "train Loss: 0.1113\n",
      "train Loss: 0.1204\n",
      "train Loss: 0.1257\n",
      "train Loss: 0.1307\n",
      "train Loss: 0.1386\n",
      "train Loss: 0.1439\n",
      "train Loss: 0.1530\n",
      "train Loss: 0.1612\n",
      "train Loss: 0.1687\n",
      "train Loss: 0.1736\n",
      "train Loss: 0.1787\n",
      "train Loss: 0.1836\n",
      "train Loss: 0.1915\n",
      "train Loss: 0.1980\n",
      "train Loss: 0.2040\n",
      "train Loss: 0.2101\n",
      "train Loss: 0.2160\n",
      "train Loss: 0.2267\n",
      "train Loss: 0.2343\n",
      "train Loss: 0.2427\n",
      "train Loss: 0.2463\n",
      "train Loss: 0.2535\n",
      "train Loss: 0.2585\n",
      "train Loss: 0.2652\n",
      "train Loss: 0.2702\n",
      "train Loss: 0.2780\n",
      "train Loss: 0.2857\n",
      "train Loss: 0.2951\n",
      "train Loss: 0.3025\n",
      "train Loss: 0.3103\n",
      "train Loss: 0.3181\n",
      "train Loss: 0.3271\n",
      "train Loss: 0.3372\n",
      "train Loss: 0.3450\n",
      "train Loss: 0.3517\n",
      "train Loss: 0.3598\n",
      "train Loss: 0.3724\n",
      "train Loss: 0.3778\n",
      "train Loss: 0.3854\n",
      "train Loss: 0.3991\n",
      "train Loss: 0.4062\n",
      "train Loss: 0.4132\n",
      "train Loss: 0.4245\n",
      "train Loss: 0.4289\n",
      "train Loss: 0.4350\n",
      "train Loss: 0.4435\n",
      "train Loss: 0.4501\n",
      "train Loss: 0.4578\n",
      "train Loss: 0.4645\n",
      "train Loss: 0.4706\n",
      "train Loss: 0.4799\n",
      "train Loss: 0.4839\n",
      "train Loss: 0.4915\n",
      "train Loss: 0.4984\n",
      "train Loss: 0.5040\n",
      "train Loss: 0.5104\n",
      "train Loss: 0.5162\n",
      "train Loss: 0.5210\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.0050\n",
      "train Loss: 0.0105\n",
      "train Loss: 0.0185\n",
      "train Loss: 0.0271\n",
      "train Loss: 0.0329\n",
      "train Loss: 0.0436\n",
      "train Loss: 0.0500\n",
      "train Loss: 0.0573\n",
      "train Loss: 0.0644\n",
      "train Loss: 0.0693\n",
      "train Loss: 0.0757\n",
      "train Loss: 0.0807\n",
      "train Loss: 0.0882\n",
      "train Loss: 0.0982\n",
      "train Loss: 0.1042\n",
      "train Loss: 0.1107\n",
      "train Loss: 0.1199\n",
      "train Loss: 0.1309\n",
      "train Loss: 0.1375\n",
      "train Loss: 0.1488\n",
      "train Loss: 0.1527\n",
      "train Loss: 0.1577\n",
      "train Loss: 0.1626\n",
      "train Loss: 0.1703\n",
      "train Loss: 0.1807\n",
      "train Loss: 0.1874\n",
      "train Loss: 0.1976\n",
      "train Loss: 0.2031\n",
      "train Loss: 0.2113\n",
      "train Loss: 0.2194\n",
      "train Loss: 0.2251\n",
      "train Loss: 0.2296\n",
      "train Loss: 0.2383\n",
      "train Loss: 0.2438\n",
      "train Loss: 0.2535\n",
      "train Loss: 0.2575\n",
      "train Loss: 0.2666\n",
      "train Loss: 0.2757\n",
      "train Loss: 0.2807\n",
      "train Loss: 0.2885\n",
      "train Loss: 0.2963\n",
      "train Loss: 0.3003\n",
      "train Loss: 0.3069\n",
      "train Loss: 0.3126\n",
      "train Loss: 0.3176\n",
      "train Loss: 0.3218\n",
      "train Loss: 0.3276\n",
      "train Loss: 0.3360\n",
      "train Loss: 0.3446\n",
      "train Loss: 0.3507\n",
      "train Loss: 0.3561\n",
      "train Loss: 0.3642\n",
      "train Loss: 0.3717\n",
      "train Loss: 0.3799\n",
      "train Loss: 0.3858\n",
      "train Loss: 0.3921\n",
      "train Loss: 0.4015\n",
      "train Loss: 0.4090\n",
      "train Loss: 0.4149\n",
      "train Loss: 0.4228\n",
      "train Loss: 0.4306\n",
      "train Loss: 0.4390\n",
      "train Loss: 0.4481\n",
      "train Loss: 0.4581\n",
      "train Loss: 0.4631\n",
      "train Loss: 0.4696\n",
      "train Loss: 0.4761\n",
      "train Loss: 0.4848\n",
      "train Loss: 0.4913\n",
      "train Loss: 0.4966\n",
      "train Loss: 0.5006\n",
      "train Loss: 0.5037\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.0113\n",
      "train Loss: 0.0163\n",
      "train Loss: 0.0226\n",
      "train Loss: 0.0317\n",
      "train Loss: 0.0398\n",
      "train Loss: 0.0459\n",
      "train Loss: 0.0554\n",
      "train Loss: 0.0618\n",
      "train Loss: 0.0708\n",
      "train Loss: 0.0761\n",
      "train Loss: 0.0840\n",
      "train Loss: 0.0925\n",
      "train Loss: 0.0989\n",
      "train Loss: 0.1037\n",
      "train Loss: 0.1095\n",
      "train Loss: 0.1160\n",
      "train Loss: 0.1251\n",
      "train Loss: 0.1300\n",
      "train Loss: 0.1364\n",
      "train Loss: 0.1423\n",
      "train Loss: 0.1492\n",
      "train Loss: 0.1562\n",
      "train Loss: 0.1599\n",
      "train Loss: 0.1672\n",
      "train Loss: 0.1729\n",
      "train Loss: 0.1800\n",
      "train Loss: 0.1846\n",
      "train Loss: 0.1903\n",
      "train Loss: 0.1967\n",
      "train Loss: 0.2020\n",
      "train Loss: 0.2115\n",
      "train Loss: 0.2212\n",
      "train Loss: 0.2271\n",
      "train Loss: 0.2326\n",
      "train Loss: 0.2392\n",
      "train Loss: 0.2479\n",
      "train Loss: 0.2549\n",
      "train Loss: 0.2630\n",
      "train Loss: 0.2680\n",
      "train Loss: 0.2732\n",
      "train Loss: 0.2836\n",
      "train Loss: 0.2927\n",
      "train Loss: 0.2973\n",
      "train Loss: 0.3045\n",
      "train Loss: 0.3157\n",
      "train Loss: 0.3249\n",
      "train Loss: 0.3328\n",
      "train Loss: 0.3389\n",
      "train Loss: 0.3456\n",
      "train Loss: 0.3522\n",
      "train Loss: 0.3574\n",
      "train Loss: 0.3668\n",
      "train Loss: 0.3723\n",
      "train Loss: 0.3793\n",
      "train Loss: 0.3854\n",
      "train Loss: 0.3924\n",
      "train Loss: 0.3997\n",
      "train Loss: 0.4053\n",
      "train Loss: 0.4143\n",
      "train Loss: 0.4223\n",
      "train Loss: 0.4338\n",
      "train Loss: 0.4367\n",
      "train Loss: 0.4441\n",
      "train Loss: 0.4509\n",
      "train Loss: 0.4557\n",
      "train Loss: 0.4629\n",
      "train Loss: 0.4694\n",
      "train Loss: 0.4794\n",
      "train Loss: 0.4863\n",
      "train Loss: 0.4948\n",
      "train Loss: 0.5012\n",
      "train Loss: 0.5041\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.0068\n",
      "train Loss: 0.0108\n",
      "train Loss: 0.0184\n",
      "train Loss: 0.0277\n",
      "train Loss: 0.0340\n",
      "train Loss: 0.0398\n",
      "train Loss: 0.0473\n",
      "train Loss: 0.0587\n",
      "train Loss: 0.0654\n",
      "train Loss: 0.0760\n",
      "train Loss: 0.0833\n",
      "train Loss: 0.0893\n",
      "train Loss: 0.0962\n",
      "train Loss: 0.1032\n",
      "train Loss: 0.1097\n",
      "train Loss: 0.1159\n",
      "train Loss: 0.1222\n",
      "train Loss: 0.1289\n",
      "train Loss: 0.1339\n",
      "train Loss: 0.1397\n",
      "train Loss: 0.1474\n",
      "train Loss: 0.1509\n",
      "train Loss: 0.1577\n",
      "train Loss: 0.1641\n",
      "train Loss: 0.1702\n",
      "train Loss: 0.1787\n",
      "train Loss: 0.1852\n",
      "train Loss: 0.1944\n",
      "train Loss: 0.2031\n",
      "train Loss: 0.2095\n",
      "train Loss: 0.2168\n",
      "train Loss: 0.2219\n",
      "train Loss: 0.2259\n",
      "train Loss: 0.2323\n",
      "train Loss: 0.2383\n",
      "train Loss: 0.2461\n",
      "train Loss: 0.2498\n",
      "train Loss: 0.2565\n",
      "train Loss: 0.2624\n",
      "train Loss: 0.2705\n",
      "train Loss: 0.2774\n",
      "train Loss: 0.2846\n",
      "train Loss: 0.2936\n",
      "train Loss: 0.2987\n",
      "train Loss: 0.3036\n",
      "train Loss: 0.3112\n",
      "train Loss: 0.3201\n",
      "train Loss: 0.3250\n",
      "train Loss: 0.3311\n",
      "train Loss: 0.3377\n",
      "train Loss: 0.3442\n",
      "train Loss: 0.3519\n",
      "train Loss: 0.3581\n",
      "train Loss: 0.3675\n",
      "train Loss: 0.3711\n",
      "train Loss: 0.3766\n",
      "train Loss: 0.3856\n",
      "train Loss: 0.3899\n",
      "train Loss: 0.3971\n",
      "train Loss: 0.4027\n",
      "train Loss: 0.4128\n",
      "train Loss: 0.4207\n",
      "train Loss: 0.4269\n",
      "train Loss: 0.4357\n",
      "train Loss: 0.4428\n",
      "train Loss: 0.4482\n",
      "train Loss: 0.4535\n",
      "train Loss: 0.4584\n",
      "train Loss: 0.4683\n",
      "train Loss: 0.4739\n",
      "train Loss: 0.4817\n",
      "train Loss: 0.4854\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.0069\n",
      "train Loss: 0.0143\n",
      "train Loss: 0.0188\n",
      "train Loss: 0.0274\n",
      "train Loss: 0.0341\n",
      "train Loss: 0.0398\n",
      "train Loss: 0.0470\n",
      "train Loss: 0.0523\n",
      "train Loss: 0.0600\n",
      "train Loss: 0.0661\n",
      "train Loss: 0.0742\n",
      "train Loss: 0.0829\n",
      "train Loss: 0.0889\n",
      "train Loss: 0.0960\n",
      "train Loss: 0.1003\n",
      "train Loss: 0.1084\n",
      "train Loss: 0.1136\n",
      "train Loss: 0.1240\n",
      "train Loss: 0.1312\n",
      "train Loss: 0.1409\n",
      "train Loss: 0.1461\n",
      "train Loss: 0.1524\n",
      "train Loss: 0.1625\n",
      "train Loss: 0.1673\n",
      "train Loss: 0.1746\n",
      "train Loss: 0.1830\n",
      "train Loss: 0.1884\n",
      "train Loss: 0.1935\n",
      "train Loss: 0.2014\n",
      "train Loss: 0.2082\n",
      "train Loss: 0.2131\n",
      "train Loss: 0.2197\n",
      "train Loss: 0.2269\n",
      "train Loss: 0.2332\n",
      "train Loss: 0.2390\n",
      "train Loss: 0.2470\n",
      "train Loss: 0.2525\n",
      "train Loss: 0.2590\n",
      "train Loss: 0.2641\n",
      "train Loss: 0.2705\n",
      "train Loss: 0.2797\n",
      "train Loss: 0.2842\n",
      "train Loss: 0.2905\n",
      "train Loss: 0.2990\n",
      "train Loss: 0.3066\n",
      "train Loss: 0.3129\n",
      "train Loss: 0.3175\n",
      "train Loss: 0.3248\n",
      "train Loss: 0.3321\n",
      "train Loss: 0.3399\n",
      "train Loss: 0.3480\n",
      "train Loss: 0.3530\n",
      "train Loss: 0.3578\n",
      "train Loss: 0.3641\n",
      "train Loss: 0.3754\n",
      "train Loss: 0.3809\n",
      "train Loss: 0.3852\n",
      "train Loss: 0.3925\n",
      "train Loss: 0.4007\n",
      "train Loss: 0.4056\n",
      "train Loss: 0.4142\n",
      "train Loss: 0.4209\n",
      "train Loss: 0.4263\n",
      "train Loss: 0.4318\n",
      "train Loss: 0.4400\n",
      "train Loss: 0.4451\n",
      "train Loss: 0.4517\n",
      "train Loss: 0.4617\n",
      "train Loss: 0.4687\n",
      "train Loss: 0.4734\n",
      "train Loss: 0.4802\n",
      "train Loss: 0.4829\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.0085\n",
      "train Loss: 0.0161\n",
      "train Loss: 0.0234\n",
      "train Loss: 0.0292\n",
      "train Loss: 0.0354\n",
      "train Loss: 0.0415\n",
      "train Loss: 0.0461\n",
      "train Loss: 0.0554\n",
      "train Loss: 0.0609\n",
      "train Loss: 0.0660\n",
      "train Loss: 0.0735\n",
      "train Loss: 0.0788\n",
      "train Loss: 0.0870\n",
      "train Loss: 0.0914\n",
      "train Loss: 0.0971\n",
      "train Loss: 0.1033\n",
      "train Loss: 0.1109\n",
      "train Loss: 0.1175\n",
      "train Loss: 0.1223\n",
      "train Loss: 0.1299\n",
      "train Loss: 0.1383\n",
      "train Loss: 0.1420\n",
      "train Loss: 0.1497\n",
      "train Loss: 0.1542\n",
      "train Loss: 0.1632\n",
      "train Loss: 0.1719\n",
      "train Loss: 0.1792\n",
      "train Loss: 0.1874\n",
      "train Loss: 0.1914\n",
      "train Loss: 0.1979\n",
      "train Loss: 0.2088\n",
      "train Loss: 0.2133\n",
      "train Loss: 0.2216\n",
      "train Loss: 0.2267\n",
      "train Loss: 0.2356\n",
      "train Loss: 0.2397\n",
      "train Loss: 0.2475\n",
      "train Loss: 0.2534\n",
      "train Loss: 0.2573\n",
      "train Loss: 0.2647\n",
      "train Loss: 0.2745\n",
      "train Loss: 0.2840\n",
      "train Loss: 0.2886\n",
      "train Loss: 0.2964\n",
      "train Loss: 0.3042\n",
      "train Loss: 0.3119\n",
      "train Loss: 0.3166\n",
      "train Loss: 0.3221\n",
      "train Loss: 0.3297\n",
      "train Loss: 0.3373\n",
      "train Loss: 0.3416\n",
      "train Loss: 0.3499\n",
      "train Loss: 0.3567\n",
      "train Loss: 0.3600\n",
      "train Loss: 0.3686\n",
      "train Loss: 0.3768\n",
      "train Loss: 0.3823\n",
      "train Loss: 0.3882\n",
      "train Loss: 0.3945\n",
      "train Loss: 0.3982\n",
      "train Loss: 0.4027\n",
      "train Loss: 0.4086\n",
      "train Loss: 0.4128\n",
      "train Loss: 0.4209\n",
      "train Loss: 0.4306\n",
      "train Loss: 0.4376\n",
      "train Loss: 0.4426\n",
      "train Loss: 0.4488\n",
      "train Loss: 0.4548\n",
      "train Loss: 0.4604\n",
      "train Loss: 0.4685\n",
      "train Loss: 0.4752\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.0054\n",
      "train Loss: 0.0117\n",
      "train Loss: 0.0175\n",
      "train Loss: 0.0243\n",
      "train Loss: 0.0336\n",
      "train Loss: 0.0386\n",
      "train Loss: 0.0454\n",
      "train Loss: 0.0513\n",
      "train Loss: 0.0568\n",
      "train Loss: 0.0613\n",
      "train Loss: 0.0645\n",
      "train Loss: 0.0706\n",
      "train Loss: 0.0788\n",
      "train Loss: 0.0840\n",
      "train Loss: 0.0913\n",
      "train Loss: 0.0962\n",
      "train Loss: 0.0996\n",
      "train Loss: 0.1051\n",
      "train Loss: 0.1094\n",
      "train Loss: 0.1175\n",
      "train Loss: 0.1230\n",
      "train Loss: 0.1306\n",
      "train Loss: 0.1382\n",
      "train Loss: 0.1447\n",
      "train Loss: 0.1539\n",
      "train Loss: 0.1595\n",
      "train Loss: 0.1682\n",
      "train Loss: 0.1747\n",
      "train Loss: 0.1799\n",
      "train Loss: 0.1844\n",
      "train Loss: 0.1898\n",
      "train Loss: 0.1983\n",
      "train Loss: 0.2018\n",
      "train Loss: 0.2106\n",
      "train Loss: 0.2147\n",
      "train Loss: 0.2222\n",
      "train Loss: 0.2304\n",
      "train Loss: 0.2361\n",
      "train Loss: 0.2445\n",
      "train Loss: 0.2523\n",
      "train Loss: 0.2588\n",
      "train Loss: 0.2644\n",
      "train Loss: 0.2698\n",
      "train Loss: 0.2796\n",
      "train Loss: 0.2835\n",
      "train Loss: 0.2913\n",
      "train Loss: 0.2988\n",
      "train Loss: 0.3049\n",
      "train Loss: 0.3125\n",
      "train Loss: 0.3214\n",
      "train Loss: 0.3293\n",
      "train Loss: 0.3384\n",
      "train Loss: 0.3446\n",
      "train Loss: 0.3518\n",
      "train Loss: 0.3549\n",
      "train Loss: 0.3626\n",
      "train Loss: 0.3689\n",
      "train Loss: 0.3773\n",
      "train Loss: 0.3823\n",
      "train Loss: 0.3903\n",
      "train Loss: 0.3985\n",
      "train Loss: 0.4052\n",
      "train Loss: 0.4131\n",
      "train Loss: 0.4218\n",
      "train Loss: 0.4291\n",
      "train Loss: 0.4382\n",
      "train Loss: 0.4433\n",
      "train Loss: 0.4469\n",
      "train Loss: 0.4548\n",
      "train Loss: 0.4621\n",
      "train Loss: 0.4675\n",
      "train Loss: 0.4745\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.0050\n",
      "train Loss: 0.0130\n",
      "train Loss: 0.0192\n",
      "train Loss: 0.0251\n",
      "train Loss: 0.0293\n",
      "train Loss: 0.0368\n",
      "train Loss: 0.0414\n",
      "train Loss: 0.0463\n",
      "train Loss: 0.0516\n",
      "train Loss: 0.0580\n",
      "train Loss: 0.0656\n",
      "train Loss: 0.0720\n",
      "train Loss: 0.0764\n",
      "train Loss: 0.0834\n",
      "train Loss: 0.0887\n",
      "train Loss: 0.0972\n",
      "train Loss: 0.1041\n",
      "train Loss: 0.1125\n",
      "train Loss: 0.1171\n",
      "train Loss: 0.1235\n",
      "train Loss: 0.1299\n",
      "train Loss: 0.1368\n",
      "train Loss: 0.1444\n",
      "train Loss: 0.1542\n",
      "train Loss: 0.1611\n",
      "train Loss: 0.1687\n",
      "train Loss: 0.1755\n",
      "train Loss: 0.1807\n",
      "train Loss: 0.1867\n",
      "train Loss: 0.1931\n",
      "train Loss: 0.1981\n",
      "train Loss: 0.2041\n",
      "train Loss: 0.2096\n",
      "train Loss: 0.2156\n",
      "train Loss: 0.2232\n",
      "train Loss: 0.2309\n",
      "train Loss: 0.2355\n",
      "train Loss: 0.2421\n",
      "train Loss: 0.2494\n",
      "train Loss: 0.2553\n",
      "train Loss: 0.2599\n",
      "train Loss: 0.2681\n",
      "train Loss: 0.2737\n",
      "train Loss: 0.2808\n",
      "train Loss: 0.2862\n",
      "train Loss: 0.2925\n",
      "train Loss: 0.2994\n",
      "train Loss: 0.3066\n",
      "train Loss: 0.3150\n",
      "train Loss: 0.3242\n",
      "train Loss: 0.3324\n",
      "train Loss: 0.3385\n",
      "train Loss: 0.3481\n",
      "train Loss: 0.3556\n",
      "train Loss: 0.3602\n",
      "train Loss: 0.3661\n",
      "train Loss: 0.3718\n",
      "train Loss: 0.3784\n",
      "train Loss: 0.3844\n",
      "train Loss: 0.3910\n",
      "train Loss: 0.3959\n",
      "train Loss: 0.4032\n",
      "train Loss: 0.4064\n",
      "train Loss: 0.4122\n",
      "train Loss: 0.4186\n",
      "train Loss: 0.4231\n",
      "train Loss: 0.4340\n",
      "train Loss: 0.4384\n",
      "train Loss: 0.4492\n",
      "train Loss: 0.4534\n",
      "train Loss: 0.4629\n",
      "train Loss: 0.4659\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.0061\n",
      "train Loss: 0.0140\n",
      "train Loss: 0.0211\n",
      "train Loss: 0.0266\n",
      "train Loss: 0.0355\n",
      "train Loss: 0.0407\n",
      "train Loss: 0.0454\n",
      "train Loss: 0.0497\n",
      "train Loss: 0.0547\n",
      "train Loss: 0.0602\n",
      "train Loss: 0.0637\n",
      "train Loss: 0.0727\n",
      "train Loss: 0.0801\n",
      "train Loss: 0.0868\n",
      "train Loss: 0.0971\n",
      "train Loss: 0.1029\n",
      "train Loss: 0.1082\n",
      "train Loss: 0.1149\n",
      "train Loss: 0.1225\n",
      "train Loss: 0.1302\n",
      "train Loss: 0.1406\n",
      "train Loss: 0.1476\n",
      "train Loss: 0.1539\n",
      "train Loss: 0.1588\n",
      "train Loss: 0.1718\n",
      "train Loss: 0.1768\n",
      "train Loss: 0.1844\n",
      "train Loss: 0.1943\n",
      "train Loss: 0.2016\n",
      "train Loss: 0.2111\n",
      "train Loss: 0.2152\n",
      "train Loss: 0.2221\n",
      "train Loss: 0.2270\n",
      "train Loss: 0.2326\n",
      "train Loss: 0.2383\n",
      "train Loss: 0.2445\n",
      "train Loss: 0.2523\n",
      "train Loss: 0.2573\n",
      "train Loss: 0.2623\n",
      "train Loss: 0.2681\n",
      "train Loss: 0.2735\n",
      "train Loss: 0.2802\n",
      "train Loss: 0.2873\n",
      "train Loss: 0.2921\n",
      "train Loss: 0.2994\n",
      "train Loss: 0.3067\n",
      "train Loss: 0.3108\n",
      "train Loss: 0.3160\n",
      "train Loss: 0.3244\n",
      "train Loss: 0.3331\n",
      "train Loss: 0.3385\n",
      "train Loss: 0.3468\n",
      "train Loss: 0.3548\n",
      "train Loss: 0.3599\n",
      "train Loss: 0.3648\n",
      "train Loss: 0.3721\n",
      "train Loss: 0.3794\n",
      "train Loss: 0.3895\n",
      "train Loss: 0.3955\n",
      "train Loss: 0.4027\n",
      "train Loss: 0.4079\n",
      "train Loss: 0.4136\n",
      "train Loss: 0.4197\n",
      "train Loss: 0.4258\n",
      "train Loss: 0.4317\n",
      "train Loss: 0.4381\n",
      "train Loss: 0.4472\n",
      "train Loss: 0.4528\n",
      "train Loss: 0.4574\n",
      "train Loss: 0.4636\n",
      "train Loss: 0.4764\n",
      "train Loss: 0.4791\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.0099\n",
      "train Loss: 0.0159\n",
      "train Loss: 0.0221\n",
      "train Loss: 0.0280\n",
      "train Loss: 0.0346\n",
      "train Loss: 0.0438\n",
      "train Loss: 0.0482\n",
      "train Loss: 0.0547\n",
      "train Loss: 0.0627\n",
      "train Loss: 0.0714\n",
      "train Loss: 0.0781\n",
      "train Loss: 0.0855\n",
      "train Loss: 0.0911\n",
      "train Loss: 0.0979\n",
      "train Loss: 0.1030\n",
      "train Loss: 0.1081\n",
      "train Loss: 0.1152\n",
      "train Loss: 0.1234\n",
      "train Loss: 0.1294\n",
      "train Loss: 0.1377\n",
      "train Loss: 0.1439\n",
      "train Loss: 0.1490\n",
      "train Loss: 0.1586\n",
      "train Loss: 0.1660\n",
      "train Loss: 0.1715\n",
      "train Loss: 0.1771\n",
      "train Loss: 0.1840\n",
      "train Loss: 0.1881\n",
      "train Loss: 0.1934\n",
      "train Loss: 0.1994\n",
      "train Loss: 0.2075\n",
      "train Loss: 0.2122\n",
      "train Loss: 0.2189\n",
      "train Loss: 0.2245\n",
      "train Loss: 0.2287\n",
      "train Loss: 0.2342\n",
      "train Loss: 0.2403\n",
      "train Loss: 0.2475\n",
      "train Loss: 0.2559\n",
      "train Loss: 0.2618\n",
      "train Loss: 0.2679\n",
      "train Loss: 0.2747\n",
      "train Loss: 0.2806\n",
      "train Loss: 0.2854\n",
      "train Loss: 0.2919\n",
      "train Loss: 0.2978\n",
      "train Loss: 0.3022\n",
      "train Loss: 0.3121\n",
      "train Loss: 0.3173\n",
      "train Loss: 0.3233\n",
      "train Loss: 0.3334\n",
      "train Loss: 0.3408\n",
      "train Loss: 0.3481\n",
      "train Loss: 0.3523\n",
      "train Loss: 0.3622\n",
      "train Loss: 0.3672\n",
      "train Loss: 0.3774\n",
      "train Loss: 0.3823\n",
      "train Loss: 0.3878\n",
      "train Loss: 0.3963\n",
      "train Loss: 0.4053\n",
      "train Loss: 0.4111\n",
      "train Loss: 0.4156\n",
      "train Loss: 0.4204\n",
      "train Loss: 0.4272\n",
      "train Loss: 0.4318\n",
      "train Loss: 0.4370\n",
      "train Loss: 0.4440\n",
      "train Loss: 0.4522\n",
      "train Loss: 0.4586\n",
      "train Loss: 0.4665\n",
      "train Loss: 0.4703\n",
      "Training complete in 19m 7s\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m mobilenet_v2_based \u001b[38;5;241m=\u001b[39m train_model(mobilenet_v2_based, criterion, optimizer_ft, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mvisualize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmobilenet_v2_based\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[1], line 125\u001b[0m, in \u001b[0;36mvisualize_model\u001b[0;34m(model, num_images)\u001b[0m\n\u001b[1;32m    122\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[1;32m    126\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    127\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'validation'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mobilenet_v2_based = train_model(mobilenet_v2_based, criterion, optimizer_ft, num_epochs=25)\n",
    "\n",
    "visualize_model(mobilenet_v2_based)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a17a04bb-e179-44d4-9317-2f560a956e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 4\n",
      "Predicted Label: plastic\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    transform = data_transforms['val']\n",
    "    preprocessed_image = transform(image)\n",
    "    preprocessed_image = preprocessed_image.unsqueeze(0)  # Add batch dimension\n",
    "    return preprocessed_image\n",
    "\n",
    "def predict_image(model, image_path):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    preprocessed_image = preprocessed_image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(preprocessed_image)\n",
    "        _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "    predicted_class = predicted_class.item()\n",
    "    predicted_label = class_names[predicted_class]\n",
    "\n",
    "    return predicted_class, predicted_label\n",
    "\n",
    "# Specify the path to the image you want to test\n",
    "image_path_to_test = \"/Users/maniksinghsarmaal/Downloads/s_bin/dataset/test/plastic/plastic404.jpg\"\n",
    "\n",
    "# Call the predict_image function\n",
    "predicted_class, predicted_label = predict_image(mobilenet_v2_based, image_path_to_test)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "print(f\"Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873388a9-abd1-4f05-acd9-17dabe6a2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path where you want to save the model\n",
    "model_save_path = \"/Users/maniksinghsarmaal/Downloads/s_bin/s_bin/mobilenetv2_model.pth\"\n",
    "\n",
    "# Save the model\n",
    "torch.save(mobilenet_v2_based.state_dict(), model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd8399-4d12-4c4e-b2d5-b494fd04b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eed9feff-1986-4a27-9ebe-62055abee976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the last layer\n",
    "number_features = mobilenet_v2_based.classifier[1].in_features\n",
    "features = list(mobilenet_v2_based.classifier.children())[:-1]  # Remove last layer\n",
    "features.extend([torch.nn.Linear(number_features, 6)])  # Set the correct number of classes\n",
    "mobilenet_v2_based.classifier = torch.nn.Sequential(*features)\n",
    "\n",
    "# Save the model\n",
    "torch.save(mobilenet_v2_based.state_dict(), model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39c3b8dd-ecd6-47db-9eb5-feef02bf0b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "loaded_model = torchvision.models.mobilenet_v2(pretrained=False)\n",
    "\n",
    "# Modify the last layer\n",
    "number_features = loaded_model.classifier[1].in_features\n",
    "features = list(loaded_model.classifier.children())[:-1]  # Remove last layer\n",
    "features.extend([torch.nn.Linear(number_features, 6)])  # Set the correct number of classes\n",
    "loaded_model.classifier = torch.nn.Sequential(*features)\n",
    "\n",
    "# Load the state dictionary\n",
    "loaded_model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453842c-4310-42b7-a795-65381c09e2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
